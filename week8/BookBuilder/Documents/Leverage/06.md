# 6 - Code Leverage


> "There is nothing so useless as doing efficiently that which should not be 
> done at all".
>
> ~ _Peter Drucker_

---

The actual activity of writing code is where implementing best practices across
an entire team can rapidly multiply your leverage on any project. By focusing on
immediate business goals and using standardized tools, your team can rapidly
turn out the highest quality software time after time. Now we'll dig into the
details of that endeavor.


## Tasks within Code Construction

Earlier we discussed the different development tasks that must be balanced
throughout the project. These tasks make up the essential work of
implementation. Coding requires four different types of fundamental activities.
Each type of task is built on a unique frame of reference. As code is built
these viewpoints must be expressed and held in balance throughout the
development cycle.

* Test - verify functionality
* Fix - repair defects and errors
* Extend - new features
* Improve - structure and performance


**Development Tasks Must be Balanced**

![Development Task Types](img/Dev_Tasks.png)

If any one of these tasks is neglected you will build up technical debt. This
can have disastrous results on a project unless it is corrected. Each of these
types of work has some key best practices associated with it. Maximum leverage
is achieved by solving the key problems in each area. Be careful to budget your
time to service each of these area with an equal amount of effort.

Each of these core perspectives has its own form of technical debt which results
from neglecting the required work. Each task also has its own best practices
that prevents the accumulation of debt. This chapter will explore each task and
show you how to overcome the related challenges.


## Test - Verify Functionality

The speed of development is directly related to the speed of your testing.
Anyone can create a large amount of code and fail to integrate it into the
overall project. Testing is central to the coding effort - without adequate
testing your team will spend a large percentage of their time trying to debug
mystery problems that come and go.

The subject of testing is so critical to development that I've dedicated the next
chapter to it. In this chapter we will focus on how testing affects the coding
process itself. We will focus on the integration of coding and testing and leave
the mechanics of testing for later.

Before a new feature is added you should think about how that feature will be
tested. Once a test has been constructed for a desired feature it is easy to
implement the feature properly. More importantly, it gives you confidence that
features that were previously working properly are still working and it will
save countless hours of debugging things that were accidentally broken.
Extensive debugging is a sign of poor test coverage.


### Begin with Tests

Before you start working in any area of the code you need to think about how
this can be tested. How will you know three months from now that the feature
isn't broken?  Writing a test lets you know when the feature is complete and
that same test will prevent the feature from being broken without you knowing
about it immediately.

Write requirements as tests. Use the tests to specify what the product must
do. Be specific about the starting and ending assumptions - the test should
reflect what you assume to be true. If you write a line of product code then
it should be tested with a line of test code. Ultimately, you will create as
much test code as product code. This is one way to get quick feedback about
the quality of your coverage. If only 10% of your code is tests then you
aren't getting adequate coverage.

Defects discovered throughout development are another piece of feedback - it
is a clue that a required test is missing. Create a test for each defect that
you discover in your product, thereby filling the gap to prevent this defect
in the future. Prevent defects from becoming repeat offenders; recidivism is
another sign of poor test coverage.


### Limit to One Line of Code

The best test is a simple one-line assertion. Verify all of the assumptions
that you believe should be true. If your assumption doesn't hold then learn
from it. A test should be simple to write and simple to correct. If you
believe that there should never be less than thirty customers in the database
or 100,000 files on the file system then express that as a single line of
code.

Test an assumption with a single assertion, you don't need to get fancy. Just
pick a test case that verifies one situation that you know must work. Each
line of product code has a test, so the tests should be short and sweet. Test
concrete examples rather that representing a large and complex set of
interactions. Our goal is to catch stuff that breaks, not to present a formal
proof of correctness. If your tests become complex, throw them away and
replace then with stacks of simple assertions.

Group related tests into a test suite. Use the module level to encapsulate
tests that match the product modules. Use functions to group things that are
testing product functions. This way the test structure roughly mirrors the
product structure. If your product has 30,000 lines of product code you will
also have another 30,000 lines of test code. Make sure that your test code is
well organized with clear correlation to your product, otherwise it code
maintenance becomes difficult.


### Testing Framework

Over time, you will gather all of the assumptions in executable form. In ten 
seconds you can verify everything that you have ever assumed about the entire
system. If you run these tests hourly then you guarantee that you know within
the hour when something unusual happens.

To make writing and running your tests efficient you will want to set up a
simple framework. It could be as simple as a test program with a thousand
assert statements. However, you will almost certainly want to have a more
convenient way to view and respond to the test failures. In the next chapter
we will lay out the specs for a system that will provide an easy way to review
and manage test results.

It is important that a single command will run all of the tests for you
quickly. Experience shows that if tests are difficult to run, they will not be
run at all. Spend the time to optimize the speed of your testing. Build your
own design rules about how long it should take to write or fix a test. Set a
time limit on how fast you need to get test results and automate the running
of tests with a system scheduler, such as Cron.

Make sure that your tests are running at least hourly. You can run complex
tests (that require a long time to execute) less frequently. But these should
also be fully automated and run daily or weekly. If the tests are not automated,
then it is unlikely that they will ever be run more than three times.

Tests are critical to your success. An adequate test battery can verify a
thousand assertions in a few seconds. You can be confident at all times that
your code is still working properly. This is extremely important when you are
leveraging the code into a new environment.


### All Tests - Every Five Minutes

Make sure that your tests run fast. By default you should force tests to yield
and answer in a second. As test times increase, developers will stop running
them and the primary value of quick testing can be easily lost. If you feel like
you need to have long running tests then cache the results. Save the results for
a hundred times as long as it took to calculate. This simple trick will allow
you to run shorter tests all the time and still run long tests occasionally.

While you are coding you should have a super-quick test that just tries the
one thing that you are working on. This should be assigned to a button press
or a command like 'x'. This will let you verify one step in less than a
second. Once the small thing works you can test the entire system in another
ten seconds. Run the small test several times a minute and then the full tests
every few minutes.

Each command that you execute has the potential to be a good test. A test is
nothing more than a coded assertion so any script can be a valid test. If the
script dies in the middle or fails to produce the expected results then it is
a failed test. A command can be repeated later with minimal effort. A test
runner can execute all tests, which makes retesting effortless. I often use
the "history" command on Linux to review recently executed commands to look
for possible new tests.


## Fix - Repair Defects and Errors

The second major task required during coding is to fix all of the problems
that are introduced. Nothing is perfect on the first attempt to implement it.
These problems must be resolved early or they will undermine the fundamental
integrity of the system.

Bugs in a system will breed like roaches so don't fail to act as you encounter
bugs. Build an urgency for defect-fixing directly into your coding process
itself. Every command that you execute will either produce an expected result
or something that you didn't anticipate. When you are surprised, stop and
investigate. This may be the only warning that you get that something is
wrong.

Logging every issue that appears is a good idea, but far too often this is the
only action taken. Why not attempt to solve the problem immediately? If you
make it your habit to solve every problem as soon as you see it then it
quickly becomes difficult to find unsolved problems to work on. This frees you
up to build more tests and more features. Remember, one defect can be hiding a
far worse one. Fix the first and the second will surface.


### Try, Fail, Recover

When you execute any command you assume that something will happen. A surprise
means that your assumption was wrong. Stop and think before you move on. Your
next action should be to verify the assumption about what just happened. Don't
neglect to acknowledge the surprise, or fail to learn from it.

Trying to write too much code before testing it is a serious mistake. Even
when you know it is wrong you can still be pulled into an attempt to write a
full block of code. Resist this urge and write one line of code at a time.
Then write a single line of test code. This method may be counter-intuitive
but you can move much faster overall.

You should expect to clear about 100 lines of code per hour when working in this
fashion. If you ever find yourself debugging and trying repeatedly to get things
working, then it is a process failure. Stop, backtrack, and start taking baby
steps again.

Each step you take should get an expected result. If you are surprised, don't
move forward until you can explain why. Fix an unexpected problem with one
line of code if possible. Try to keep the edit/test loop going at least once a
minute.


### Adjust Scope Based on Each Trial

Don't make repeated attempts to solve a problem. Instead, change the context.
After two failures, isolate one part that you suspect may be causing the
failure. Zoom in on the problem by changing the execution context. Keep
executing less and less code until you have a test case that executes one line
of code and demonstrates the problem.

Consider the example of importing a file with employees in it. The error
message says 'Import Failed on record 24'. The natural impulse is to start
changing random things and trying to import the file over and over again.
Instead, try to feed line 24 directly into the import record function. By
doing this, we have moved from a "read table" context to a "read record"
context. With this approach you're more likely to quickly find something
useful like the issue is with the name lookup during the import.

Keep zooming in until you find and fix the problem. Then zoom out to each level
that previously failed. Eventually, all of the tests that were failing will
pass. Save the test cases in your test suite and never again will this problem
happen without you knowing instantly.

Here are some simple rules for your development loop:

* Reduce scope of context after each failure
* Enlarge scope of test after each success
* Don't attempt multiple fixes in the same context
* Minimize the code in each iteration
* Enlarge the scope all the way up to the full product test
* Debugging is a red flag indicator of poor testing
* Run the loop each minute
* Sprint and rest
* Measure your output


### Goal Stack

It is often helpful to keep a goal stack while working on a new feature or
resolving a defect. Things come up and require your immediate attention, but
once resolved you want to switch your attention back to the previous goal.
This is a lot like how subroutines work.

Start with the biggest goal. Then each new issue causes you to push the stack.
Resolving an issue pops the stack and the stack itself provides a reminder of
how you got here.

Example Goal Stack:

* Build authentication system for users  <- highest level goal
* Build login user story
* Create http://xxx.com/login
* Build Django login view
* Fix CSRF issue with page
* Enable Django middleware to allow CSRF handling
* Research issue on Stack Overflow  <- lowest level goal

Start by selecting a single product feature to work on. Avoid all distractions
until this feature is created, tested, integrated, and committed to version
control. Try to break the larger feature into smaller parts, then push the
first part on the stack. Focus on just the current task before you add a bunch
of other tasks to the list.

Push new problems on the stack as they interrupt the work in progress. Try not
to let the stack get too deep since this represents open mind share that
requires energy to manage. When the current problem is solved then pop the
stack. An empty stack means that you can select the next feature. This process
will drive full closure on the work in progress before starting new work.


### Seek Closure

Coding is a complex task and there are a lot of minor issues that must be
resolved in order to get closure. Multitasking can be a major source of
defects because of a fundamental limitation of the human brain. Trying to
focus on more than one thing at a time rapidly decreases the effectiveness of
cognitive ability. Therefore, concentrate on a single area until it is fully
implemented.
 
Balance the different types of work required for a given feature. Make sure
that Test, Fix, Extend, and Improve goals are all matched. Don't neglect
fixing issues or writing tests. Solve these issues while your brain is fully
loaded with the details of the problems. The best time to refactor any given
area is immediately after adding new functionality. Improve structure before
you leave the area. Resolve work in progress now so there is no lingering
doubt about its status.


## Extend - New Features

The third major task during coding is to add new features to the system. This
should start by creating a quick test that tells us whether the feature is
working properly. Most features should be implemented in several levels of
detail so that complex features are composed of smaller ones.

Extending the product will involve implementing each of the sub-features making
up the larger ones. Just as the high-level features should start with a test, so
should each of the detailed features. Think about the features as being defined
by an outline of requirements. Each requirement should have a test case that
defines when the requirement is fully complete.

The coding proceeds from the most detailed features to the highest-level
features in the system. After everything is complete then all the tests will
pass and the code can be committed to version control. This development loop
allows you to quickly iterate over hundreds of specific features rapidly to
reach the end goal.


### Personal Automation

We all face many problems that could be fully automated. As programmers, we
have an array of tools at our disposal that could be easily used to script any
repeatable task. If you have to repeat a series of steps, create a script to
do the task for you. Automation is a great personal tool for removing any
routine tasks from your daily work flow.

Some tasks are simple enough that we never think of automating them. But even
simple tasks carry a burden of memory and judgment that may either be forgotten
or misapplied when needed. Even when it is done correctly it still creates a
mental burden. Consider the following shell script:

    copy_files:
        rsync -auv My_System:Projects/Hammer/ ~/Projects/Hammer

This script copies files that are newer from one directory on another system to
my system recursively. Note the density of the encoded knowledge and design
trade-offs. Sure, you could type it in each time you needed it... but why?
Running 'copy_files' gets you the result that you want without thinking about
how this is accomplished.

Generating scripts gets you to a phenomenal level of code leverage. I have
been investing heavily in automation over the last few years and now I have my
own command language that has a vocabulary of well over 1,000 scripts. Almost
anything that needs to be done can be accomplished with two words on the command
line.

You may not need to go quite that far in order to achieve impressive results.
Automation will pay huge dividends - one hour spent automating will typically
return ten hours within a month.


### Code Generation

We run into many cases where we can use a parameterized template to create
unique code. All web frameworks and IDEs have built-in tools that can be used
to generate code using a template. It is also quite easy to build your own code
generators in Python, Ruby, Shell, or PERL. If your problem has some boiler-
plate code in it then avoid generating this code by hand.

A scripting language can let you capture the commands that you enter manually
on the command line and turn these into a script. For example, if you are
working to set up a computer you may execute many commands before you find
the winning recipe. Once you find it the code may be reused as a script.

    history > setup

Set your context so that it is easy to create, edit, and execute commands.
Make sure that the commands are created in a place where they can be
automatically executed without ceremony. Imagine having a script that sets up
a new command for you from the command line.

    cmd-add list 'List my files' 'ls $xxx'

If the code that is created has repeating structures within it, you may find
it useful to write a simple script that creates the repeating code for you.
These scripts can often be plugged directly into your text editor to extend
your ability to write code. Think like a programmer when you are writing code
- if you can simplify the task of writing by creating a short script that
writes the code for you, do it!

The final type of code generation to consider is creating programs to
transform existing code. These are often based on regular expressions. A
simple program can save work because it can be filed away and resurrected or
created when needed. These programs may start out very trivial but often
evolve quickly into something that is vital to the project. They frequently
end up as embedded tools in a larger automated effort. Consider the following
simple example.

    Fixer.py:

    from sys import stdin
    text = stdin.read()
    text = text.replace('this','that')
    text = text.replace('-','_')
    print text


### Static Analysis Tools

Source code is encoded knowledge - it expresses a solution to a problem in
some type of a programming language. There are tools that can analyze the
language itself to give us insight into the structure of our code. We can
learn a lot from analyzing the code that we produce by catching errors and
revealing inefficiencies in our coding.

Style checkers can be used to look for superficial problems within our code.
We can look for formatting issues and simple design rules violations. The Lint
family of tools are unique to each programming language environment. These do
a thorough analysis of the correct usage of the language and they can detect
everything from uninitialized variables to bad return values.

You should be using these tools and building them into your project
infrastructure so that they run automatically. Learn how to suppress the
errors that you aren't interested in. It can be a pain to set these tools up
the first time, but their presence can prevent a lot of errors over the long
term.

The last essential set of tools will help you monitor the complexity of your
code over time. Later in this chapter we will discuss how you can best manage
your source code complexity. Each of these individual tools will give you good
results and combining them together will create a great toolkit for
productivity.


### Editing Code

There is a seemingly endless debate about using a simple editor or an IDE
(integrated development environment). I have been in both camps so I'll just
say pick the tool that helps you get the job done quickest. In fact, it can be
very beneficial to switch between them. If you are an IDE guru, consider
switching to Sublime, and the reverse.

An IDE isolates you from technical details, while a programmer's editor makes
it easy to build your own tools. Both of these tool types offer advantages and
both of them come with limitations. If you are skilled at both types of tools
then you will have a sense for when one will be more effective than another.

The editing environment must support a productive work flow. This requires a few
key features. Your work flow must let you have an extremely fast development
loop. You need to be able to edit the code and run the tests in less than 3
seconds. This means that the source code and executable program must be visible
at the same time.

Other features that you need for a modern editor are color syntax and command
completion. These tools act as an extension of your brain during coding and
save a significant amount of time. The final useful feature is refactoring
tools like the ones built into the JetBrains products. These will help save a
great deal of time by doing the grunt work of editing during refactoring.

The most essential features for editing:

* Fast Edit/Test loop  (two windows works fine)
* Add a snippet (using a template with parameters)
* Color syntax highlighting
* Command completion and API lookup
* Jump to definition and usage
* Plug in built tools for transforming code
* Refactoring tools
* Static analysis
* Integrated debugger


### Rapid Prototyping

Rapid prototyping is valuable because a new system is often far easier to
create than modifying an existing one. After all, the new system has minimal
complexity while the existing product may have hundreds of constraints. A new
problem can be solved quickly by creating a new environment where there is a
simple context available.

Once a problem is fully solved then the source code can be moved from the simple
test application into the product. Consider using the following process to
build each new feature:

* Isolate - build a stand-alone app that just contains the desired feature
* Invent - create detailed feature set that is desired
* Integrate - combine your new code with the existing product logic
* Regression tests - save all of the test logic so that it can be run hourly

A full-featured product will emerge much quicker with a rapid prototype
process. Each time that you have an idea to try out you can generate a stand-
alone app that lets you work on the idea all by itself. Think of it as a work
bench where you can experiment with new product ideas - this doesn't need to be
the same as the product context.

You should be able to create an entire prototype in less than a day. This
gives you the ability to try out a new application idea with a very small
investment. You should be able to go from the raw business idea to a running
application that embodies the core functionality very quickly.

A work bench application lets you experiment with specific algorithms in
isolation. Your product domain will dictate the specific data types that your
application should support. For example, if your technology area is imaging
you will need a work bench for trying out the effect of different image
transforms.

Our goal is not simply to get to the first product quickly, but to create tools
that will let us produce a family of products quickly. Solve the meta-problems
in order to encourage the largest possible leverage. Think about code prototyping
capabilities that will benefit you now and two years from now. Then build the
tools that you are missing today.


## Improve - Structure and Performance

The final task of coding is to make improvements to the structure and
performance of the system. Many engineers are happy once the features work
properly and they fail to work on the underlying structure. Over time, each
feature introduces an unpaid technical debt. The only way to prevent this from
happening is to commit about a quarter of the coding time to refactoring the
code.

Refactoring is often viewed as an optional phase and just extra unnecessary
work. However, improving the structure of the code is as necessary as building
the product features. If the structure decays with each edit the system will
very quickly be rendered useless. No software can be reused when it is riddled
with structural flaws and duplicated code. Structural improvement is mandatory
if you intend to have any leverage at all. Each time you add a feature make
some small structural improvement to the immediate area. This guarantees that
the more you touch it the better the code will get.


### Build Reusable Components

Creating reusable code isn't difficult because there are a few simple
principles that govern the flexibility of code. Code that is well-encapsulated
can be used in environments that differ drastically from the original context.
Code that isn't connected to all of its surroundings won't break when the
context changes. This is the most important principle for code reuse.

The next principle that enables us to reuse code is to have a clear way to
extend the functionality beyond its first usage. You must be able to flex the
code in a new direction that doesn't risk breaking everything that was already
working. Build the proper amount of flexibility into the design because some
applications have a higher need for flexibility than others. Code that can't
be tested easily will never be flexible.

Components must be testable as stand-alone code. Testing components only in
the primary application that they are built for is completely inadequate
because there are far too many special conditions that must be exercised to
feel confident about the testing. Automatic tests are necessary for each
software component in the system - you must be able to validate each
part in isolation.

Every system has a few key interfaces that do most of the work. Consider
building a language to interact with the key elements of your API. This lets
you build scenarios to create data in your system, capture key traffic across
the interface, and playback transactions from earlier recordings. These remote
control capabilities can greatly extend the reuse of your software.

Consider building a simple program that exercises a particular interface and
use it for many different purposes. Interacting with a component directly,
rather than indirectly through the rest of the system, can be very
enlightening and is useful in a wide variety of debugging and analysis
scenarios.


### Refactoring

Refactoring is the primary skill required to improve software. Without this
ability you are doomed to creating software that can't be maintained. Project
managers frequently don't understand the value of refactoring, but it is a
vital part of any development. Refactoring is what keeps your product healthy
over the long term.

The power of refactoring is built on having a comprehensive set of unit tests.
It is impossible to do large-scale refactoring without tests. You may be able
to get the code running properly at the start, but you will never have the
confidence that all of the code is working in every case. After a disaster
strikes your project the decision makers may come to the false conclusion that
refactoring was the cause of the failure. This can cause you to lose support
for any future refactoring operations and without refactoring your system
will quickly become both rigid and fragile.

Refactoring is the key to flexibility. By continuously making small
adjustments to your system structure, the system can remain healthy
indefinitely. If you stop making improvements to your structure then the
design is etched in stone and can't adapt to the changing world. It is
imperative that your design remains flexible. Your product won't meet its
fundamental goals unless it can be maintained over time.

The end state of most refactoring work is to eliminate duplication. This comes
in many forms in the software. Learn to recognize the smell of duplication
within the code:

* Lines of code that are repeated
* Algorithms that are written more than once
* Similar logic patterns that should be consolidated into a function
* Poor encapsulation that will cause future duplication


Build your own catalog of refactorings. Here are the most useful refactorings
in my catalog:

* Extract code into a function
* Move function to another file
* Rename function
* Rename variable
* Pass state as a parameter


### Complexity

Systems naturally grow more complex over time. Because complexity lowers quality,
it makes the system more costly to maintain. Complexity must be managed
throughout the development cycle in order to control costs and preserve quality.
Yet, in most organizations there is a lack of appreciation for the impact that
code complexity can have on a project.

Complexity is the key driver of software quality. If your system is complex it
will be far more costly to build and maintain. The cost of a system grows
exponentially with the complexity. If you want to control something, you need
to be able to measure it. For this reason, I believe that it is vital to have
a complexity measure that can be computed within 5 seconds.

We need to start by understanding what causes complexity in the first place so
we can use a tool to measure the complexity of the code. The complexity
measures will point out areas of the code that need to be redesigned. Finally,
we can develop simple rules that all engineers can use to constantly decrease
complexity.

There has been a great deal of good computer science research on code
complexity. McCabe and Halstead have developed well-calibrated methods of
computing complexity numbers. In practice, I think this degree of rigor is
seldom needed. Instead, consider simple metrics that can be computed in real
time by a script.

Complexity comes from all of the combinations of all of the bits of logic that
occur in our systems. Complexity is driven by two main forces - the size of
the system and the connections between different parts of the system.

I like simple tools that allow me to reason through a system. Even if they
don't produce “accurate” results, they will produce useful results. Over time,
we can learn to interpret the results within a given context. We can use this
principle to build our own custom measurement for complexity. In **Appendix
A** you will find step by step instructions for how to build a code complexity
measurement tool that is customized to your application. This can be altered
to reflect your own perception of what complexity means in your world.

The major advantage of building your own complexity measurement tool is that
you can start simple and evolve your own understanding of what makes your code
complex. Your opinions about complexity can be directly reflected in your
measurement tool. Over time you can steer the design to reflect the attributes
that are most valuable to you.

The complexity metrics will help you understand the source code better. Each
module is listed with a corresponding measure of its complexity so the tool
points out modules that are far more complex than their neighbors. The exact
value of the measurements are less important than the relative ranking of the
modules.

Run the tool repeatedly and develop simple rules. When a module gets too
complex, restructure it. Create a threshold that triggers an automatic review
or rewrite. These metrics serve as an analysis tool to increase your
understanding of the underlying dynamics of your code. Regular usage will make
you adept at finding and fixing hot spots. Over time your complexity will
decrease simply because you are paying attention to it.

The exact values produced by the metrics mean nothing, but by quantifying the
complexity, it creates a baseline of knowledge. Build this understanding over
time and use it as a key method of steering the project.

Remember that cost scales with complexity - decrease the complexity in order
to decrease the cost. This simple tool will point you to the biggest areas for
improvement. Then, focus all of your energy on the most complex parts rather
than trying to simplify everything.

     Complexity => Risk => Cost

Make this incremental simplification a normal part of every day. Replacing a
complex thing with a simple thing will make everything better. Imagine the
effect of 1,000 minor improvement to your project. Each lowers the risk to
your project and collectively they can easily yield a profound reduction in
cost.


### Version Control

Version control tools are the most under-appreciated tools in programming.
Embracing the strategic value of version control can dramatically accelerate
your leverage. Modern tools like Git, Mercurial, and Subversion are at the
pinnacle of a long string of tools that began in the 1970s. Make sure that you
are using one of these tools and begin to build your entire development stack
around the version control tool. I will refer to 'git' throughout the
remainder of this book but any of the modern tools will suffice.

Source code is anything that is a fundamental expression of the design. The
source code is combined with the tool chain to produce the deployed product.
In essence, the tool chain itself is a part of the source code. However, the
tools are not usually stored under version control since the exact versions of
the tools can be installed from scratch when needed.

Source code also includes all of the operations information, such as server
configurations and update scripts. Anything that is needed to produce the
running software must be either versioned or readily installable from another
source. It is important to have automatic processes to setup and configure all
of the different types of servers with the required tools.

Like everything else, we trust but verify. Never believe that you can build the
product from scratch unless you do it weekly. Your entire build process must be
fully automated and run periodically. Tear down the world and reconstruct it
with nothing more than the git repository and required hardware.

Version control is the one point of integration - it is the primary method for
developers to coordinate with each other. The developers should have clear
rules about how to branch and merge. Divergence is the enemy so you should try
to integrate code hourly. At the same time, you also want to clearly identify
when it is appropriate to work on a development, integration, or staging
branch. Proper rules for how to use version control is too important to be
left up to chance - it won't just evolve on its own. Develop your own custom
set of practices and train each engineer on the correct techniques.


## Best Practice #6 - _Use a balanced approach to development resulting in
minimum code complexity._


***Problem***<br>
Developers will often be sensitive to one aspect of the software while
neglecting others. This can easily create an illusion of rapid progress.
However, late in the life cycle the project will start to fall apart. This is
a symptom of problems with the software process from the very beginning of the
project that only become apparent when it is the most difficult to correct.

Poor process results in lopsided development and is responsible for creating
pockets of complexity within the system that make the overall product hard to
understand. Most long-term maintenance problems can be tied to complex designs
that have been implemented by complex code. As time progresses the complexity
of the code will threaten its very viability and cause an early replacement of
the entire system.

Most teams don't have a clear picture for the code complexity because it isn't
being measured or managed. Yet, complexity is at the heart of many quality
problems. Improving structure and performance require that code complexity is
readily visible.

***Solution***<br>
Let complexity measurement drive development. Complexity is a problem that can
easily be solved. The first step is to have a tool that can reveal the most
complex areas of any code so the problem areas can be simplified. Once a
complexity measure is in place it prevents new code from becoming complex
without anyone being made aware of it.

Legacy code that was written at an earlier time can be simplified as well. A
balanced approach to software development requires that developers pursue the
clean up of structural issues and fixing defects at the same time they are
building the system. In the case of legacy code, a certain amount of remedial
work is required to create tests and fix structural problems before any new
functionality can be added. This makes working with legacy code more expensive
than starting a new app from scratch.

Whether you are building from scratch or working with legacy code, you must be
able to refactor. This requires the development practices to support it. If
you can't refactor and evolve your code it is only a matter of time before
complexity takes over your system and your only choice will be to replace it.


***Next Steps***

* Conduct a self assessment of time spent on: Test, Fix, Extend, Improve
* Select the most critical area for process improvement
* Measure your test code (in lines) and compare it to your product code
* Measure and assess the number of open defects on your project
* Try out either the dev loop or goal stack idea to accelerate coding
* Implement a complexity metric for your source code

